{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TinyQuant Quickstart"
      ],
      "metadata": {
        "id": "FxlYa8eK05oJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpfEX60Q01gL"
      },
      "outputs": [],
      "source": [
        "%pip install -q \"tinyquant@git+https://github.com/galqiwi/tinyquant\"\n",
        "%pip install -q bitsandbytes transformers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers"
      ],
      "metadata": {
        "id": "frSM_k_H1YOD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"unsloth/Llama-3.2-1B\"\n",
        "\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"cuda\",\n",
        "    dtype=torch.bfloat16,\n",
        ")\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "dvpTD6wG1kI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tinyquant.utils import quantize_matching_linear_layers\n",
        "quantize_matching_linear_layers(model, \"nf4\", \"model.layers.*.self_attn.q_proj\")"
      ],
      "metadata": {
        "id": "eTwXqLVf1y7e"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = model.generate(\n",
        "    tokenizer(\"2+2=\", return_tensors=\"pt\")[\"input_ids\"].cuda(),\n",
        "    max_new_tokens=10,\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(output[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y14QZ64s2XrR",
        "outputId": "e50c568a-3aab-4b8a-b274-5bbaf93f51dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|>2+2=4. The number of variables is equal to the\n"
          ]
        }
      ]
    }
  ]
}