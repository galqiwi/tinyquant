{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxlYa8eK05oJ"
   },
   "source": [
    "# TinyQuant Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GpfEX60Q01gL"
   },
   "outputs": [],
   "source": [
    "%pip install -q \"tinyquant@git+https://github.com/galqiwi/tinyquant\"\n",
    "%pip install -q bitsandbytes transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "frSM_k_H1YOD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvpTD6wG1kI_"
   },
   "outputs": [],
   "source": [
    "model_id = \"unsloth/Llama-3.2-1B\"\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"cuda\",\n",
    "    dtype=torch.bfloat16,\n",
    ")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eTwXqLVf1y7e"
   },
   "outputs": [],
   "source": [
    "from tinyquant.utils import quantize_matching_linear_layers\n",
    "\n",
    "quantize_matching_linear_layers(model, \"nf4\", \"model.layers.*.self_attn.q_proj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y14QZ64s2XrR",
    "outputId": "e50c568a-3aab-4b8a-b274-5bbaf93f51dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>2+2=4. The number of variables is equal to the\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(\n",
    "    tokenizer(\"2+2=\", return_tensors=\"pt\")[\"input_ids\"].cuda(),\n",
    "    max_new_tokens=10,\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(output[0]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}